{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8593304,"sourceType":"datasetVersion","datasetId":5140452}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers rouge_score peft huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-17T09:11:18.818915Z","iopub.execute_input":"2024-07-17T09:11:18.819821Z","iopub.status.idle":"2024-07-17T09:11:36.003163Z","shell.execute_reply.started":"2024-07-17T09:11:18.819761Z","shell.execute_reply":"2024-07-17T09:11:36.002172Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=41a4ad664f73f098e64a766eb4fe6feefe8050415cd0b11fe4acb16fa779e9e7\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, peft\nSuccessfully installed peft-0.11.1 rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# import huggingface_hub\n\n# huggingface_hub.login(\"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\", add_to_git_credential=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T09:58:16.076885Z","iopub.execute_input":"2024-07-16T09:58:16.077561Z","iopub.status.idle":"2024-07-16T09:58:16.081746Z","shell.execute_reply.started":"2024-07-16T09:58:16.077505Z","shell.execute_reply":"2024-07-16T09:58:16.080685Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel, AutoModelForSeq2SeqLM, MBartForConditionalGeneration, AutoTokenizer, pipeline, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq,TrainingArguments,  T5ForConditionalGeneration, Trainer, get_cosine_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:11:36.005129Z","iopub.execute_input":"2024-07-17T09:11:36.005444Z","iopub.status.idle":"2024-07-17T09:11:55.816922Z","shell.execute_reply.started":"2024-07-17T09:11:36.005413Z","shell.execute_reply":"2024-07-17T09:11:55.815915Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-17 09:11:43.616984: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-17 09:11:43.617099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-17 09:11:43.765272: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import *\nfrom torch.nn import *\nfrom sklearn.metrics import *\nimport numpy as np\nimport torch\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:12:07.054508Z","iopub.execute_input":"2024-07-17T09:12:07.054883Z","iopub.status.idle":"2024-07-17T09:12:07.060033Z","shell.execute_reply.started":"2024-07-17T09:12:07.054853Z","shell.execute_reply":"2024-07-17T09:12:07.058997Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"seed = 221\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:12:08.272220Z","iopub.execute_input":"2024-07-17T09:12:08.272588Z","iopub.status.idle":"2024-07-17T09:12:08.281256Z","shell.execute_reply.started":"2024-07-17T09:12:08.272556Z","shell.execute_reply":"2024-07-17T09:12:08.280438Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"vinBART = \"vinai/bartpho-syllable-base\"\nmt5 = \"chibao24/vietnamese_mt5_summary_model\"\nvit5 = \"VietAI/vit5-base\"","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:12:08.824897Z","iopub.execute_input":"2024-07-17T09:12:08.825264Z","iopub.status.idle":"2024-07-17T09:12:08.830982Z","shell.execute_reply.started":"2024-07-17T09:12:08.825235Z","shell.execute_reply":"2024-07-17T09:12:08.830052Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(vinBART)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:12:09.588980Z","iopub.execute_input":"2024-07-17T09:12:09.589847Z","iopub.status.idle":"2024-07-17T09:12:12.204344Z","shell.execute_reply.started":"2024-07-17T09:12:09.589816Z","shell.execute_reply":"2024-07-17T09:12:12.203539Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/898 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abaaa7ddb9134ec0aba95667eb41b338"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c42b9ae722754838a483d1c929a03adb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.txt:   0%|          | 0.00/360k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7b672bcbdf492bb276b24523b80498"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bb87a1f264e4bf4916addc27fac1621"}},"metadata":{}}]},{"cell_type":"code","source":"model = MBartForConditionalGeneration.from_pretrained(vinBART).to(\"cuda\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:12:12.205712Z","iopub.execute_input":"2024-07-17T09:12:12.205972Z","iopub.status.idle":"2024-07-17T09:12:15.740032Z","shell.execute_reply.started":"2024-07-17T09:12:12.205949Z","shell.execute_reply":"2024-07-17T09:12:15.739053Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/526M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59061c4a9960427da08d92012a8de6d9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(r\"/kaggle/input/summarization-vn/dataset/train.csv\")\ntest = pd.read_csv(r\"/kaggle/input/summarization-vn/dataset/test.csv\")\n\ntrain = train[train[\"summary\"].notnull()]\ntest = test[test[\"summary\"].notnull()]\n\ndef length(row):\n    return len(row.split(\" \"))\n\ntrain[\"length_con\"] = train[\"content\"].apply(length)\ntrain[\"length_sum\"] = train[\"summary\"].apply(length)\n\ntest[\"length_con\"] = test[\"content\"].apply(length)\ntest[\"length_sum\"] = test[\"summary\"].apply(length)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:12:15.741844Z","iopub.execute_input":"2024-07-17T09:12:15.742227Z","iopub.status.idle":"2024-07-17T09:12:26.533712Z","shell.execute_reply.started":"2024-07-17T09:12:15.742193Z","shell.execute_reply":"2024-07-17T09:12:26.532665Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(train[(train[\"length_sum\"] < 112) & (train[\"length_con\"] < 417)])","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:14:50.636744Z","iopub.execute_input":"2024-07-17T09:14:50.637574Z","iopub.status.idle":"2024-07-17T09:14:50.650407Z","shell.execute_reply.started":"2024-07-17T09:14:50.637544Z","shell.execute_reply":"2024-07-17T09:14:50.649315Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"23561"},"metadata":{}}]},{"cell_type":"code","source":"train = train[(train[\"length_sum\"] < 112) & (train[\"length_con\"] < 417)]","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:15:35.764877Z","iopub.execute_input":"2024-07-17T09:15:35.765271Z","iopub.status.idle":"2024-07-17T09:15:35.792769Z","shell.execute_reply.started":"2024-07-17T09:15:35.765240Z","shell.execute_reply":"2024-07-17T09:15:35.791875Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:15:38.536547Z","iopub.execute_input":"2024-07-17T09:15:38.536917Z","iopub.status.idle":"2024-07-17T09:15:38.555965Z","shell.execute_reply.started":"2024-07-17T09:15:38.536886Z","shell.execute_reply":"2024-07-17T09:15:38.555125Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         length_con    length_sum\ncount  23561.000000  23561.000000\nmean     223.512499     82.817283\nstd       94.183263     18.646231\nmin        9.000000      2.000000\n25%      150.000000     71.000000\n50%      218.000000     85.000000\n75%      296.000000     98.000000\nmax      416.000000    111.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>length_con</th>\n      <th>length_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>23561.000000</td>\n      <td>23561.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>223.512499</td>\n      <td>82.817283</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>94.183263</td>\n      <td>18.646231</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>9.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>150.000000</td>\n      <td>71.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>218.000000</td>\n      <td>85.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>296.000000</td>\n      <td>98.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>416.000000</td>\n      <td>111.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.drop(columns=[\"length_con\", \"length_sum\"], axis = 1, inplace=True)\ntest.drop(columns=[\"length_con\", \"length_sum\"], axis = 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:17:46.819183Z","iopub.execute_input":"2024-07-17T09:17:46.820028Z","iopub.status.idle":"2024-07-17T09:17:46.825308Z","shell.execute_reply.started":"2024-07-17T09:17:46.819982Z","shell.execute_reply":"2024-07-17T09:17:46.824340Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# sample = 15000\n# train = train.sample(n=sample, random_state=seed)\n# test = test.sample(n=int(sample*0.2), random_state=123)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:17:28.481684Z","iopub.execute_input":"2024-07-17T09:17:28.482568Z","iopub.status.idle":"2024-07-17T09:17:28.491866Z","shell.execute_reply.started":"2024-07-17T09:17:28.482532Z","shell.execute_reply":"2024-07-17T09:17:28.490935Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:17:56.717936Z","iopub.execute_input":"2024-07-17T09:17:56.718788Z","iopub.status.idle":"2024-07-17T09:17:56.733996Z","shell.execute_reply.started":"2024-07-17T09:17:56.718758Z","shell.execute_reply":"2024-07-17T09:17:56.733045Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 15000 entries, 44248 to 32071\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   content  15000 non-null  object\n 1   summary  15000 non-null  object\ndtypes: object(2)\nmemory usage: 351.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# max_length = 0\n# for index, row in test.iterrows():\n#     if(len(row[\"content\"].split()) > max_length):\n#         max_length = len(row[\"content\"].split())\n# max_length","metadata":{"execution":{"iopub.status.busy":"2024-07-16T09:59:03.851036Z","iopub.execute_input":"2024-07-16T09:59:03.851358Z","iopub.status.idle":"2024-07-16T09:59:03.857059Z","shell.execute_reply.started":"2024-07-16T09:59:03.851314Z","shell.execute_reply":"2024-07-16T09:59:03.856218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train[\"content\"] = train[\"content\"].apply(lambda x: \"summarize: \" + x)\ntest[\"content\"] = test[\"content\"].apply(lambda x: \"summarize: \" + x)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:18:13.792615Z","iopub.execute_input":"2024-07-17T09:18:13.792990Z","iopub.status.idle":"2024-07-17T09:18:13.822058Z","shell.execute_reply.started":"2024-07-17T09:18:13.792959Z","shell.execute_reply":"2024-07-17T09:18:13.821278Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\ndef preprocess_function(examples):\n    \n    model_inputs = tokenizer(\n        examples[\"content\"], \n        max_length=418, \n        truncation=True, \n        padding='max_length',\n        return_tensors=\"pt\"  \n    )\n    \n    labels = tokenizer(\n        examples[\"summary\"], \n        max_length=113, \n        truncation=True, \n        padding='max_length',\n        return_tensors=\"pt\"  \n    )\n    \n    model_inputs[\"labels\"] = labels['input_ids']\n    \n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:18:18.364449Z","iopub.execute_input":"2024-07-17T09:18:18.364810Z","iopub.status.idle":"2024-07-17T09:18:18.370531Z","shell.execute_reply.started":"2024-07-17T09:18:18.364780Z","shell.execute_reply":"2024-07-17T09:18:18.369504Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ntrain = Dataset.from_pandas(train)\ntest = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:18:21.108602Z","iopub.execute_input":"2024-07-17T09:18:21.109228Z","iopub.status.idle":"2024-07-17T09:18:21.470160Z","shell.execute_reply.started":"2024-07-17T09:18:21.109197Z","shell.execute_reply":"2024-07-17T09:18:21.469362Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"tokenized_train = train.map(preprocess_function, batched=True, remove_columns=[\"content\", \"summary\"])\ntokenized_test = test.map(preprocess_function, batched=True, remove_columns=[\"content\", \"summary\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:18:22.095804Z","iopub.execute_input":"2024-07-17T09:18:22.096181Z","iopub.status.idle":"2024-07-17T09:19:02.303940Z","shell.execute_reply.started":"2024-07-17T09:18:22.096151Z","shell.execute_reply":"2024-07-17T09:19:02.303045Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04463fb2f1e847e2bcdf238141d8260d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/981 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30e54d4fceab4476b7d9063fd038d677"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:19:02.305471Z","iopub.execute_input":"2024-07-17T09:19:02.305755Z","iopub.status.idle":"2024-07-17T09:19:02.312051Z","shell.execute_reply.started":"2024-07-17T09:19:02.305729Z","shell.execute_reply":"2024-07-17T09:19:02.311176Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n\ntrain_dataloader = DataLoader(tokenized_train, shuffle=True ,batch_size = 8)\ntest_dataloader = DataLoader(tokenized_test, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:19:02.313409Z","iopub.execute_input":"2024-07-17T09:19:02.313985Z","iopub.status.idle":"2024-07-17T09:19:02.323348Z","shell.execute_reply.started":"2024-07-17T09:19:02.313948Z","shell.execute_reply":"2024-07-17T09:19:02.322463Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, weight_decay = 0.01)\nlr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = 500, num_training_steps = 3 , num_cycles=5)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:19:02.324892Z","iopub.execute_input":"2024-07-17T09:19:02.325167Z","iopub.status.idle":"2024-07-17T09:19:02.334430Z","shell.execute_reply.started":"2024-07-17T09:19:02.325144Z","shell.execute_reply":"2024-07-17T09:19:02.333714Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from torch.cuda.amp import GradScaler, autocast\nfrom tqdm.auto import tqdm\nepochs = 3\naccumulation_steps = 20\nscaler = GradScaler()\n\nmodel.train()\n\n\nprogress_bar = tqdm(total=len(train_dataloader) * epochs)\n\nfor epoch in range(epochs):\n    for i, batch in enumerate(train_dataloader):\n        batch = {k: v.to('cuda') for k, v in batch.items()}\n\n        with autocast():  # Enable mixed precision\n            outputs = model(**batch)\n            loss = outputs.loss / accumulation_steps  # Normalize loss by accumulation steps\n\n        scaler.scale(loss).backward()\n\n        if (i + 1) % accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            lr_scheduler.step()\n            torch.cuda.empty_cache()  # Clear cache to free memory\n\n        progress_bar.update(1)\n\n    torch.cuda.empty_cache()  # Clear cache after each epoch\n\nprogress_bar.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:19:05.584534Z","iopub.execute_input":"2024-07-17T09:19:05.585176Z","iopub.status.idle":"2024-07-17T09:47:00.872570Z","shell.execute_reply.started":"2024-07-17T09:19:05.585144Z","shell.execute_reply":"2024-07-17T09:47:00.871633Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3afa27b1df40da81b787db90f712f6"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_metric\nfrom prettytable import PrettyTable\n\nmetric = load_metric(\"rouge\")\n\nmodel.eval()\n\nfor batch in test_dataloader:\n    batch = {k: v.to('cuda') for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model.generate(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], max_length = 120)\n        \n    decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n\n    metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n\nfinal_score = metric.compute()\n\n\ntable = PrettyTable()\ntable.field_names = [\"Metric\", \"Precision\", \"Recall\", \"F1 Score\"]\n\n# Add rows for each ROUGE metric\nfor rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n    scores = final_score[rouge_type]\n    table.add_row([\n        rouge_type.upper(),\n        f\"{scores.mid.precision:.4f}\",\n        f\"{scores.mid.recall:.4f}\",\n        f\"{scores.mid.fmeasure:.4f}\"\n    ])\n\n# Print the table\nprint(table)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:47:04.969671Z","iopub.execute_input":"2024-07-17T09:47:04.970038Z","iopub.status.idle":"2024-07-17T09:49:07.150602Z","shell.execute_reply.started":"2024-07-17T09:47:04.969997Z","shell.execute_reply":"2024-07-17T09:49:07.149700Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1186520021.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"rouge\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3b00c91e7864e6788eb64489f01beed"}},"metadata":{}},{"name":"stdout","text":"+--------+-----------+--------+----------+\n| Metric | Precision | Recall | F1 Score |\n+--------+-----------+--------+----------+\n| ROUGE1 |   0.7522  | 0.7286 |  0.7297  |\n| ROUGE2 |   0.4925  | 0.4760 |  0.4776  |\n| ROUGEL |   0.5274  | 0.5114 |  0.5114  |\n+--------+-----------+--------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/\")\ntokenizer.save_pretrained(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:50:45.048721Z","iopub.execute_input":"2024-07-17T09:50:45.049119Z","iopub.status.idle":"2024-07-17T09:50:45.063902Z","shell.execute_reply.started":"2024-07-17T09:50:45.049086Z","shell.execute_reply":"2024-07-17T09:50:45.063039Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/tokenizer_config.json',\n '/kaggle/working/special_tokens_map.json',\n '/kaggle/working/sentencepiece.bpe.model',\n '/kaggle/working/dict.txt',\n '/kaggle/working/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# inputs = input()\n\n# tokenized_input = tokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:57:48.575391Z","iopub.execute_input":"2024-07-17T09:57:48.575759Z","iopub.status.idle":"2024-07-17T09:57:49.713462Z","shell.execute_reply.started":"2024-07-17T09:57:48.575731Z","shell.execute_reply":"2024-07-17T09:57:49.712509Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdin","text":" Mặc dù ra đời sau các Frameword khác như TensorFlow và Keras nhưng Pytorch đã có cho mình chỗ đứng nhất định trong cộng đồng các nhà nghiên cứu bởi lý do sau:  So với Keras và TensorFlow thì Pytorch, với tính năng hỗ trợ autograd của nó đã giúp các nhà nghiên cứu tùy chỉnh linh hoạt, dễ dàng tùy theo từng trường hợp. Hơn nữa, Pytorch còn cung cấp cho người dùng toàn quyền kiểm soát vòng lặp đào tạo.  PyTorch có một cộng đồng người dùng và cộng tác viên đông đảo, cung cấp nhiều tài nguyên và hỗ trợ người dùng trong các cuộc nghiên cứu. Đặc biệt, PyTorch còn có thể dễ dàng tích hợp với các thư viện khác như NumPy và Caffe2 để triển khai các mô hình trong nhiều môi trường khác nhau.\n"}]},{"cell_type":"code","source":"# pipe = pipeline(task=\"summarization\", model = model, tokenizer = tokenizer, device = 0)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:54:40.115097Z","iopub.execute_input":"2024-07-17T09:54:40.115770Z","iopub.status.idle":"2024-07-17T09:54:40.121031Z","shell.execute_reply.started":"2024-07-17T09:54:40.115737Z","shell.execute_reply":"2024-07-17T09:54:40.120052Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# pipe(inputs, max_length = 150)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:57:53.420286Z","iopub.execute_input":"2024-07-17T09:57:53.421110Z","iopub.status.idle":"2024-07-17T09:57:54.027235Z","shell.execute_reply.started":"2024-07-17T09:57:53.421073Z","shell.execute_reply":"2024-07-17T09:57:54.026271Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': 'Pytorch là một nhà nghiên cứu có thể tạo ra các Frameword khác như TensorFlow và Keras nhưng vẫn có một cộng đồng người dùng và cộng tác viên đông đảo, cung cấp nhiều tài nguyên và hỗ trợ người dùng trong các cuộc nghiên cứu. PyTorch có thể dễ dàng tích hợp với các thư viện khác như NumPy và Caffe2 để triển khai các mô hình trong nhiều môi trường khác nhau.'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# LOra finetune","metadata":{}},{"cell_type":"code","source":"# from peft import LoraConfig, LoraModel, get_peft_model\n# config = LoraConfig(\n#     task_type = \"SEQ_2_SEQ_LM\",\n#     r = 8,\n#     lora_alpha = 32,\n#     target_modules=[\"k_proj\", \"q_proj\", \"v_proj\"],\n#     lora_dropout=0.01,\n# )\n# for param in model.parameters():\n#     # freeze base model's layers\n#     param.requires_grad = False\n\n# if hasattr(model, \"enable_input_require_grads\"):\n#     model.enable_input_require_grads()\n# else:\n#     def make_inputs_require_grad(module, input, output):\n#             output.requires_grad_(True)\n#     model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)\n        \n# peft_model = get_peft_model(model, config)\n# peft_model.print_trainable_parameters()\n# peft_model.config.use_cache = False \n# peft_model = peft_model.to(\"cuda\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T09:59:49.782940Z","iopub.execute_input":"2024-07-16T09:59:49.783426Z","iopub.status.idle":"2024-07-16T09:59:49.878641Z","shell.execute_reply.started":"2024-07-16T09:59:49.783395Z","shell.execute_reply":"2024-07-16T09:59:49.877730Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"trainable params: 663,552 || all params: 132,226,560 || trainable%: 0.5018\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# batch_size = 16\n# epoch = 3\n# import copy\n\n# gen_config = copy.deepcopy(model.generation_config)\n# gen_config.update(\n#     max_new_tokens=499,\n#     max_length = 499,\n#     early_stopping=False,\n#     num_beams=1,\n#     no_repeat_ngram_size=0,\n# )\n\n\n# args = Seq2SeqTrainingArguments(\n#     output_dir = \"TaiDepZai999-UIT-Vit5\",\n# #     learning_rate = 5e-5,\n# #     warmup_steps = 500,\n# #     weight_decay=0.01,\n#     per_device_train_batch_size = batch_size,\n#     per_device_eval_batch_size = batch_size,\n#     num_train_epochs = epoch,\n#     seed = seed,\n#     eval_strategy=\"epoch\",\n#     generation_config=gen_config,\n# #     push_to_hub=True,\n#     save_total_limit=3,\n#     predict_with_generate=True,\n#     fp16=True,\n#     gradient_accumulation_steps=4,\n#     gradient_checkpointing=True,\n\n# )\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T10:00:29.962038Z","iopub.execute_input":"2024-07-16T10:00:29.962754Z","iopub.status.idle":"2024-07-16T10:00:29.992875Z","shell.execute_reply.started":"2024-07-16T10:00:29.962723Z","shell.execute_reply":"2024-07-16T10:00:29.992074Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# import nltk\n# from nltk.tokenize import sent_tokenize\n# from rouge_score import rouge\n# from datasets import load_metric\n# nltk.download('punkt')\n\n\n# def compute_metrics(eval_pred):\n#     predictions, labels = eval_pred\n#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n#     rouge = load_metric(\"rouge\")\n#     result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n#     result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n#     return result","metadata":{"execution":{"iopub.status.busy":"2024-07-16T10:00:31.281631Z","iopub.execute_input":"2024-07-16T10:00:31.282525Z","iopub.status.idle":"2024-07-16T10:00:31.865805Z","shell.execute_reply.started":"2024-07-16T10:00:31.282478Z","shell.execute_reply":"2024-07-16T10:00:31.864905Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# key = \"fdef48fc279db0325237791cb3cbefa589ad0c92\"\n# import wandb\n# wandb.login(key=key)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T10:00:32.590716Z","iopub.execute_input":"2024-07-16T10:00:32.591447Z","iopub.status.idle":"2024-07-16T10:00:35.936311Z","shell.execute_reply.started":"2024-07-16T10:00:32.591418Z","shell.execute_reply":"2024-07-16T10:00:35.935339Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# data_collator = DataCollatorForSeq2Seq(\n#     tokenizer,\n#     model = peft_model,\n#     return_tensors = \"pt\"\n# )\n\n\n# trainer = Seq2SeqTrainer(\n#     peft_model,\n#     args,\n#     train_dataset = tokenized_train,\n#     eval_dataset = tokenized_test,\n#     compute_metrics=compute_metrics,\n#     tokenizer = tokenizer,\n#     data_collator=data_collator,\n#     optimizers=(optimizer, lr_scheduler)\n# )\n# trainer.train()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.push_to_hub(\"NBTailee/TaiDepZai999-UIT-Vit5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}